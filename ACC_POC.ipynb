{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Frames from Videos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "#video_name = \"awarpur/4.mp4\" # or any other extension like .avi etc\n",
    "vidcap = cv2.VideoCapture(video_name)\n",
    "success,image = vidcap.read()\n",
    "count = 3067\n",
    "while success:\n",
    "  cv2.imwrite(\"frames/vid1/frame%d.jpg\" % count, image)     # save frame as JPEG file      \n",
    "  success,image = vidcap.read()\n",
    "  print('Read a new frame: ', success)\n",
    "  count += 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model inferencing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "from time import time\n",
    "from ultralytics import YOLO\n",
    "\n",
    "from supervision.draw.color import ColorPalette\n",
    "from supervision.tools.detections import Detections, BoxAnnotator\n",
    "\n",
    "torch.cuda.set_per_process_memory_fraction(0.1, device=0)\n",
    "class ObjectDetection:\n",
    "\n",
    "    def __init__(self, capture_index):\n",
    "       \n",
    "        self.capture_index = capture_index\n",
    "        \n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        print(\"Using Device: \", self.device)\n",
    "        \n",
    "        self.model = self.load_model()\n",
    "        \n",
    "        self.CLASS_NAMES_DICT = self.model.model.names\n",
    "    \n",
    "        self.box_annotator = BoxAnnotator(color=ColorPalette(), thickness=3, text_thickness=3, text_scale=1.5)\n",
    "    \n",
    "\n",
    "    def load_model(self):\n",
    "       \n",
    "        model = YOLO(\"M:/CV/ACC_POC/weights/yolo8n_100epochs.pt\")  # load a pretrained YOLOv8n model\n",
    "        model.fuse()\n",
    "    \n",
    "        return model\n",
    "\n",
    "\n",
    "    def predict(self, frame):\n",
    "       \n",
    "        results = self.model(frame)\n",
    "        \n",
    "        return results\n",
    "    \n",
    "\n",
    "    def plot_bboxes(self, results, frame):\n",
    "        \n",
    "        xyxys = []\n",
    "        confidences = []\n",
    "        class_ids = []\n",
    "        \n",
    "        # Extract detections for person class\n",
    "        for result in results[0]:\n",
    "            class_id = result.boxes.cls.cpu().numpy().astype(int)\n",
    "            \n",
    "            if class_id == 0:\n",
    "                \n",
    "                xyxys.append(result.boxes.xyxy.cpu().numpy())\n",
    "                confidences.append(result.boxes.conf.cpu().numpy())\n",
    "                class_ids.append(result.boxes.cls.cpu().numpy().astype(int))\n",
    "            \n",
    "        \n",
    "        # Setup detections for visualization\n",
    "        detections = Detections(\n",
    "                    xyxy=results[0].boxes.xyxy.cpu().numpy(),\n",
    "                    confidence=results[0].boxes.conf.cpu().numpy(),\n",
    "                    class_id=results[0].boxes.cls.cpu().numpy().astype(int),\n",
    "                    )\n",
    "        \n",
    "    \n",
    "        # Format custom labels\n",
    "        self.labels = [f\"{self.CLASS_NAMES_DICT[class_id]} {confidence:0.2f}\"\n",
    "        for _, confidence, class_id, tracker_id\n",
    "        in detections]\n",
    "        \n",
    "        # Annotate and display frame\n",
    "        frame = self.box_annotator.annotate(frame=frame, detections=detections, labels=self.labels)\n",
    "        \n",
    "        return frame\n",
    "    \n",
    "    \n",
    "    \n",
    "    def __call__(self):\n",
    "\n",
    "        cap = cv2.VideoCapture(self.capture_index)\n",
    "        assert cap.isOpened()\n",
    "        cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)\n",
    "        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)\n",
    "      \n",
    "        while True:\n",
    "          \n",
    "            start_time = time()\n",
    "            \n",
    "            ret, frame = cap.read()\n",
    "            assert ret\n",
    "            \n",
    "            results = self.predict(frame)\n",
    "            frame = self.plot_bboxes(results, frame)\n",
    "            \n",
    "            end_time = time()\n",
    "            fps = 1/np.round(end_time - start_time, 2)\n",
    "             \n",
    "            cv2.putText(frame, f'FPS: {int(fps)}', (20,70), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0,255,0), 2)\n",
    "            \n",
    "            cv2.imshow('YOLOv8 Detection', frame)\n",
    " \n",
    "            if cv2.waitKey(5) & 0xFF == 27:\n",
    "                \n",
    "                break\n",
    "        \n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        \n",
    "        \n",
    "    \n",
    "#detector = ObjectDetection(capture_index=0)\n",
    "detector = ObjectDetection(capture_index='M:/CV/ACC_POC/videos/4.mp4')\n",
    "detector()\n",
    "\n",
    "#'M:/CV/ACC_POC/videos/4.mp4'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detect obj and predict result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "from time import time\n",
    "from ultralytics import YOLO\n",
    "\n",
    "from supervision.draw.color import ColorPalette\n",
    "from supervision.tools.detections import Detections, BoxAnnotator\n",
    "\n",
    "\n",
    "class ObjectDetection:\n",
    "\n",
    "    def __init__(self, capture_index):\n",
    "       \n",
    "        self.capture_index = capture_index\n",
    "        \n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        print(\"Using Device: \", self.device)\n",
    "        \n",
    "        self.model = self.load_model()\n",
    "        \n",
    "        self.CLASS_NAMES_DICT = self.model.model.names\n",
    "    \n",
    "        self.box_annotator = BoxAnnotator(color=ColorPalette(), thickness=3, text_thickness=3, text_scale=1.5)\n",
    "    \n",
    "\n",
    "    def load_model(self):\n",
    "       \n",
    "        model = YOLO(\"M:/CV/ACC_POC/weights/best.pt\")  # load a pretrained YOLOv8n model\n",
    "        model.fuse()\n",
    "    \n",
    "        return model\n",
    "\n",
    "\n",
    "    def predict(self, frame):\n",
    "       \n",
    "        results = self.model(frame)\n",
    "        \n",
    "        return results\n",
    "    \n",
    "\n",
    "    def plot_bboxes(self, results, frame):\n",
    "        \n",
    "        xyxys = []\n",
    "        confidences = []\n",
    "        class_ids = []\n",
    "        \n",
    "        # Extract detections for person class\n",
    "        for result in results[0]:\n",
    "            class_id = result.boxes.cls.cpu().numpy().astype(int)\n",
    "            \n",
    "            if class_id == 0:\n",
    "                \n",
    "                xyxys.append(result.boxes.xyxy.cpu().numpy())\n",
    "                confidences.append(result.boxes.conf.cpu().numpy())\n",
    "                class_ids.append(result.boxes.cls.cpu().numpy().astype(int))\n",
    "            \n",
    "        \n",
    "        # Setup detections for visualization\n",
    "        detections = Detections(\n",
    "                    xyxy=results[0].boxes.xyxy.cpu().numpy(),\n",
    "                    confidence=results[0].boxes.conf.cpu().numpy(),\n",
    "                    class_id=results[0].boxes.cls.cpu().numpy().astype(int),\n",
    "                    )\n",
    "        \n",
    "    \n",
    "        # Format custom labels\n",
    "        self.labels = [f\"{self.CLASS_NAMES_DICT[class_id]} {confidence:0.2f}\"\n",
    "        for _, confidence, class_id, tracker_id\n",
    "        in detections]\n",
    "        \n",
    "        # Annotate and display frame\n",
    "        frame = self.box_annotator.annotate(frame=frame, detections=detections, labels=self.labels)\n",
    "        \n",
    "        return frame\n",
    "    \n",
    "    \n",
    "    \n",
    "    def __call__(self):\n",
    "\n",
    "        cap = cv2.VideoCapture(self.capture_index)\n",
    "        assert cap.isOpened()\n",
    "        cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)\n",
    "        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)\n",
    "      \n",
    "        while True:\n",
    "          \n",
    "            start_time = time()\n",
    "            \n",
    "            ret, frame = cap.read()\n",
    "            assert ret\n",
    "            \n",
    "            results = self.predict(frame)\n",
    "            frame = self.plot_bboxes(results, frame)\n",
    "            \n",
    "            end_time = time()\n",
    "            fps = 1/np.round(end_time - start_time, 2)\n",
    "             \n",
    "            cv2.putText(frame, f'FPS: {int(fps)}', (20,70), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0,255,0), 2)\n",
    "            \n",
    "            cv2.imshow('YOLOv8 Detection', frame)\n",
    " \n",
    "            if cv2.waitKey(5) & 0xFF == 27:\n",
    "                \n",
    "                break\n",
    "        \n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        \n",
    "        \n",
    "    \n",
    "detector = ObjectDetection(capture_index='M:/CV/ACC_POC/videos/4.mp4')\n",
    "detector()\n",
    "\n",
    "#'M:/CV/ACC_POC/videos/4.mp4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model summary (fused): 168 layers, 3006038 parameters, 0 gradients, 8.1 GFLOPs\n",
      "Ultralytics YOLOv8.0.38  Python-3.8.16 torch-1.13.1+cpu CPU\n",
      "\n",
      "0: 640x512 82.2ms\n",
      "Speed: 0.2ms pre-process, 82.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([], size=(0, 6))\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "from time import time\n",
    "from ultralytics import YOLO\n",
    "\n",
    "from supervision.draw.color import ColorPalette\n",
    "from supervision.tools.detections import Detections, BoxAnnotator\n",
    "\n",
    "\n",
    "\n",
    "model = YOLO(\"M:/CV/ACC_POC/weights/yolo8n_200epochs.pt\")  # load a pretrained YOLOv8n model\n",
    "model.fuse()\n",
    "\n",
    "frame1=cv2.imread('571.jpg')\n",
    "results=model(frame1)\n",
    "print(results[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "not one\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'helmet', 1: 'no_helmet'}\n"
     ]
    }
   ],
   "source": [
    "class_names=model.model.names\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bboxes(self, results, frame):\n",
    "    \n",
    "    xyxys = []\n",
    "    confidences = []\n",
    "    class_ids = []\n",
    "    \n",
    "    # Extract detections for person class\n",
    "    for result in results[0]:\n",
    "        class_id = result.boxes.cls.cpu().numpy().astype(int)\n",
    "        \n",
    "        if class_id == 0:\n",
    "            \n",
    "            xyxys.append(result.boxes.xyxy.cpu().numpy())\n",
    "            confidences.append(result.boxes.conf.cpu().numpy())\n",
    "            class_ids.append(result.boxes.cls.cpu().numpy().astype(int))\n",
    "        \n",
    "    \n",
    "    # Setup detections for visualization\n",
    "    detections = Detections(\n",
    "                xyxy=results[0].boxes.xyxy.cpu().numpy(),\n",
    "                confidence=results[0].boxes.conf.cpu().numpy(),\n",
    "                class_id=results[0].boxes.cls.cpu().numpy().astype(int),\n",
    "                )\n",
    "    \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Device:  cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model summary (fused): 168 layers, 11126358 parameters, 0 gradients, 28.4 GFLOPs\n",
      "Ultralytics YOLOv8.0.38  Python-3.8.16 torch-1.13.1+cpu CPU\n",
      "\n",
      "0: 480x640 154.3ms\n",
      "Speed: 1.4ms pre-process, 154.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 163.0ms\n",
      "Speed: 0.0ms pre-process, 163.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 157.3ms\n",
      "Speed: 0.0ms pre-process, 157.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 155.7ms\n",
      "Speed: 0.0ms pre-process, 155.7ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 156.3ms\n",
      "Speed: 1.1ms pre-process, 156.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 152.7ms\n",
      "Speed: 1.0ms pre-process, 152.7ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 145.7ms\n",
      "Speed: 1.0ms pre-process, 145.7ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 146.3ms\n",
      "Speed: 0.0ms pre-process, 146.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 163.1ms\n",
      "Speed: 1.0ms pre-process, 163.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 150.4ms\n",
      "Speed: 1.4ms pre-process, 150.4ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 143.3ms\n",
      "Speed: 1.0ms pre-process, 143.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 151.4ms\n",
      "Speed: 1.0ms pre-process, 151.4ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 151.3ms\n",
      "Speed: 0.0ms pre-process, 151.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 150.6ms\n",
      "Speed: 0.0ms pre-process, 150.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 149.0ms\n",
      "Speed: 1.0ms pre-process, 149.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 150.5ms\n",
      "Speed: 0.0ms pre-process, 150.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 152.5ms\n",
      "Speed: 1.0ms pre-process, 152.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 148.0ms\n",
      "Speed: 1.0ms pre-process, 148.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 148.6ms\n",
      "Speed: 1.0ms pre-process, 148.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 140.8ms\n",
      "Speed: 0.0ms pre-process, 140.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 147.2ms\n",
      "Speed: 0.0ms pre-process, 147.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 147.9ms\n",
      "Speed: 0.0ms pre-process, 147.9ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 151.5ms\n",
      "Speed: 1.0ms pre-process, 151.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 145.2ms\n",
      "Speed: 1.1ms pre-process, 145.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 149.2ms\n",
      "Speed: 0.0ms pre-process, 149.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 138.4ms\n",
      "Speed: 0.0ms pre-process, 138.4ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 146.8ms\n",
      "Speed: 1.0ms pre-process, 146.8ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 152.8ms\n",
      "Speed: 1.2ms pre-process, 152.8ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 145.7ms\n",
      "Speed: 1.0ms pre-process, 145.7ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 150.1ms\n",
      "Speed: 0.0ms pre-process, 150.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 141.6ms\n",
      "Speed: 1.5ms pre-process, 141.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 146.5ms\n",
      "Speed: 1.0ms pre-process, 146.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 151.6ms\n",
      "Speed: 1.1ms pre-process, 151.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 151.0ms\n",
      "Speed: 0.0ms pre-process, 151.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 150.9ms\n",
      "Speed: 0.0ms pre-process, 150.9ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 150.5ms\n",
      "Speed: 0.0ms pre-process, 150.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 149.1ms\n",
      "Speed: 0.0ms pre-process, 149.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 147.5ms\n",
      "Speed: 1.0ms pre-process, 147.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 155.2ms\n",
      "Speed: 0.0ms pre-process, 155.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 158.0ms\n",
      "Speed: 0.0ms pre-process, 158.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 153.7ms\n",
      "Speed: 0.0ms pre-process, 153.7ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 152.3ms\n",
      "Speed: 1.0ms pre-process, 152.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 152.9ms\n",
      "Speed: 1.5ms pre-process, 152.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 144.3ms\n",
      "Speed: 1.0ms pre-process, 144.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 149.6ms\n",
      "Speed: 0.0ms pre-process, 149.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 156.3ms\n",
      "Speed: 0.0ms pre-process, 156.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 152.8ms\n",
      "Speed: 0.0ms pre-process, 152.8ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 152.7ms\n",
      "Speed: 1.4ms pre-process, 152.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 152.6ms\n",
      "Speed: 0.0ms pre-process, 152.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 147.4ms\n",
      "Speed: 0.0ms pre-process, 147.4ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 155.5ms\n",
      "Speed: 0.0ms pre-process, 155.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 158.3ms\n",
      "Speed: 1.0ms pre-process, 158.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 154.1ms\n",
      "Speed: 1.0ms pre-process, 154.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 149.7ms\n",
      "Speed: 1.0ms pre-process, 149.7ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 154.2ms\n",
      "Speed: 0.0ms pre-process, 154.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 152.6ms\n",
      "Speed: 1.0ms pre-process, 152.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 152.6ms\n",
      "Speed: 1.0ms pre-process, 152.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 149.9ms\n",
      "Speed: 1.0ms pre-process, 149.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 142.7ms\n",
      "Speed: 0.0ms pre-process, 142.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 149.1ms\n",
      "Speed: 1.1ms pre-process, 149.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 154.0ms\n",
      "Speed: 0.0ms pre-process, 154.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 151.1ms\n",
      "Speed: 1.0ms pre-process, 151.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 149.8ms\n",
      "Speed: 1.0ms pre-process, 149.8ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 146.8ms\n",
      "Speed: 1.5ms pre-process, 146.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 152.7ms\n",
      "Speed: 0.0ms pre-process, 152.7ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 153.1ms\n",
      "Speed: 1.0ms pre-process, 153.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 150.9ms\n",
      "Speed: 0.0ms pre-process, 150.9ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 148.4ms\n",
      "Speed: 0.0ms pre-process, 148.4ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 144.8ms\n",
      "Speed: 0.0ms pre-process, 144.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 150.0ms\n",
      "Speed: 0.0ms pre-process, 150.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 148.1ms\n",
      "Speed: 0.0ms pre-process, 148.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 150.6ms\n",
      "Speed: 0.0ms pre-process, 150.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 152.2ms\n",
      "Speed: 1.0ms pre-process, 152.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 147.5ms\n",
      "Speed: 1.4ms pre-process, 147.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 158.3ms\n",
      "Speed: 0.0ms pre-process, 158.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 147.0ms\n",
      "Speed: 1.0ms pre-process, 147.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 162.1ms\n",
      "Speed: 1.0ms pre-process, 162.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 147.8ms\n",
      "Speed: 1.1ms pre-process, 147.8ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 147.6ms\n",
      "Speed: 0.0ms pre-process, 147.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 147.7ms\n",
      "Speed: 1.0ms pre-process, 147.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 150.3ms\n",
      "Speed: 0.0ms pre-process, 150.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 144.2ms\n",
      "Speed: 0.0ms pre-process, 144.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 151.4ms\n",
      "Speed: 0.0ms pre-process, 151.4ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 148.5ms\n",
      "Speed: 1.0ms pre-process, 148.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 144.1ms\n",
      "Speed: 2.4ms pre-process, 144.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 152.9ms\n",
      "Speed: 1.0ms pre-process, 152.9ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 154.9ms\n",
      "Speed: 0.0ms pre-process, 154.9ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 143.3ms\n",
      "Speed: 1.0ms pre-process, 143.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 148.5ms\n",
      "Speed: 0.0ms pre-process, 148.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 157.2ms\n",
      "Speed: 0.0ms pre-process, 157.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 152.4ms\n",
      "Speed: 0.0ms pre-process, 152.4ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 148.7ms\n",
      "Speed: 0.0ms pre-process, 148.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 145.7ms\n",
      "Speed: 0.0ms pre-process, 145.7ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 153.6ms\n",
      "Speed: 1.4ms pre-process, 153.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 148.2ms\n",
      "Speed: 0.0ms pre-process, 148.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 147.3ms\n",
      "Speed: 1.0ms pre-process, 147.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 149.9ms\n",
      "Speed: 1.0ms pre-process, 149.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 146.7ms\n",
      "Speed: 1.0ms pre-process, 146.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 148.3ms\n",
      "Speed: 1.5ms pre-process, 148.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 152.4ms\n",
      "Speed: 0.0ms pre-process, 152.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 147.1ms\n",
      "Speed: 0.0ms pre-process, 147.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 148.8ms\n",
      "Speed: 1.0ms pre-process, 148.8ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 151.2ms\n",
      "Speed: 0.5ms pre-process, 151.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 149.0ms\n",
      "Speed: 0.0ms pre-process, 149.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 149.7ms\n",
      "Speed: 0.0ms pre-process, 149.7ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 150.5ms\n",
      "Speed: 0.0ms pre-process, 150.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 150.9ms\n",
      "Speed: 1.0ms pre-process, 150.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 152.1ms\n",
      "Speed: 1.2ms pre-process, 152.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 148.6ms\n",
      "Speed: 0.0ms pre-process, 148.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 146.0ms\n",
      "Speed: 0.0ms pre-process, 146.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 147.8ms\n",
      "Speed: 0.0ms pre-process, 147.8ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 149.1ms\n",
      "Speed: 1.0ms pre-process, 149.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 155.9ms\n",
      "Speed: 0.0ms pre-process, 155.9ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 146.1ms\n",
      "Speed: 0.0ms pre-process, 146.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 147.8ms\n",
      "Speed: 1.0ms pre-process, 147.8ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 151.3ms\n",
      "Speed: 1.0ms pre-process, 151.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 143.4ms\n",
      "Speed: 1.0ms pre-process, 143.4ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 141.3ms\n",
      "Speed: 1.0ms pre-process, 141.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 148.2ms\n",
      "Speed: 1.0ms pre-process, 148.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 151.2ms\n",
      "Speed: 0.0ms pre-process, 151.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 148.4ms\n",
      "Speed: 0.0ms pre-process, 148.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 143.0ms\n",
      "Speed: 0.0ms pre-process, 143.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 149.3ms\n",
      "Speed: 1.2ms pre-process, 149.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 144.6ms\n",
      "Speed: 1.0ms pre-process, 144.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 148.0ms\n",
      "Speed: 1.0ms pre-process, 148.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 144.7ms\n",
      "Speed: 0.0ms pre-process, 144.7ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 150.7ms\n",
      "Speed: 0.0ms pre-process, 150.7ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 147.0ms\n",
      "Speed: 0.5ms pre-process, 147.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 149.3ms\n",
      "Speed: 0.0ms pre-process, 149.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 147.0ms\n",
      "Speed: 0.0ms pre-process, 147.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 150.8ms\n",
      "Speed: 0.0ms pre-process, 150.8ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 148.1ms\n",
      "Speed: 0.0ms pre-process, 148.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 148.3ms\n",
      "Speed: 0.0ms pre-process, 148.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 151.4ms\n",
      "Speed: 0.0ms pre-process, 151.4ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 143.4ms\n",
      "Speed: 0.5ms pre-process, 143.4ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 152.0ms\n",
      "Speed: 0.0ms pre-process, 152.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 148.7ms\n",
      "Speed: 0.0ms pre-process, 148.7ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 145.0ms\n",
      "Speed: 1.0ms pre-process, 145.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 166.3ms\n",
      "Speed: 0.0ms pre-process, 166.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 148.0ms\n",
      "Speed: 1.0ms pre-process, 148.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 147.6ms\n",
      "Speed: 1.0ms pre-process, 147.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 148.0ms\n",
      "Speed: 1.0ms pre-process, 148.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 148.1ms\n",
      "Speed: 0.0ms pre-process, 148.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 151.0ms\n",
      "Speed: 1.0ms pre-process, 151.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 152.4ms\n",
      "Speed: 1.2ms pre-process, 152.4ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 146.7ms\n",
      "Speed: 1.5ms pre-process, 146.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 148.1ms\n",
      "Speed: 0.0ms pre-process, 148.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 211.8ms\n",
      "Speed: 1.0ms pre-process, 211.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 157.6ms\n",
      "Speed: 0.0ms pre-process, 157.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 144.8ms\n",
      "Speed: 0.0ms pre-process, 144.8ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 148.3ms\n",
      "Speed: 1.0ms pre-process, 148.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 149.6ms\n",
      "Speed: 1.2ms pre-process, 149.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 151.0ms\n",
      "Speed: 0.0ms pre-process, 151.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 159.6ms\n",
      "Speed: 0.0ms pre-process, 159.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 159.1ms\n",
      "Speed: 1.4ms pre-process, 159.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 147.7ms\n",
      "Speed: 1.0ms pre-process, 147.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 148.6ms\n",
      "Speed: 1.0ms pre-process, 148.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 145.5ms\n",
      "Speed: 0.5ms pre-process, 145.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 150.2ms\n",
      "Speed: 1.5ms pre-process, 150.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 152.3ms\n",
      "Speed: 0.0ms pre-process, 152.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 154.8ms\n",
      "Speed: 0.0ms pre-process, 154.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 147.7ms\n",
      "Speed: 0.0ms pre-process, 147.7ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 151.5ms\n",
      "Speed: 1.1ms pre-process, 151.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 152.8ms\n",
      "Speed: 0.0ms pre-process, 152.8ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 150.2ms\n",
      "Speed: 0.3ms pre-process, 150.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 144.1ms\n",
      "Speed: 1.0ms pre-process, 144.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 149.3ms\n",
      "Speed: 1.0ms pre-process, 149.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 149.0ms\n",
      "Speed: 0.0ms pre-process, 149.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 157.1ms\n",
      "Speed: 0.0ms pre-process, 157.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 147.7ms\n",
      "Speed: 0.5ms pre-process, 147.7ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 145.9ms\n",
      "Speed: 1.0ms pre-process, 145.9ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 145.1ms\n",
      "Speed: 1.0ms pre-process, 145.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 144.2ms\n",
      "Speed: 0.0ms pre-process, 144.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 145.3ms\n",
      "Speed: 1.0ms pre-process, 145.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 145.9ms\n",
      "Speed: 0.0ms pre-process, 145.9ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 148.6ms\n",
      "Speed: 0.0ms pre-process, 148.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 148.6ms\n",
      "Speed: 0.0ms pre-process, 148.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 144.7ms\n",
      "Speed: 1.3ms pre-process, 144.7ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 147.6ms\n",
      "Speed: 0.0ms pre-process, 147.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 143.2ms\n",
      "Speed: 0.0ms pre-process, 143.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 148.4ms\n",
      "Speed: 1.0ms pre-process, 148.4ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 147.4ms\n",
      "Speed: 1.0ms pre-process, 147.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 155.9ms\n",
      "Speed: 1.1ms pre-process, 155.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 143.3ms\n",
      "Speed: 1.0ms pre-process, 143.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 147.5ms\n",
      "Speed: 0.0ms pre-process, 147.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 192.7ms\n",
      "Speed: 0.0ms pre-process, 192.7ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 153.9ms\n",
      "Speed: 1.0ms pre-process, 153.9ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 151.6ms\n",
      "Speed: 1.3ms pre-process, 151.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 151.2ms\n",
      "Speed: 2.3ms pre-process, 151.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 150.2ms\n",
      "Speed: 1.0ms pre-process, 150.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 149.0ms\n",
      "Speed: 0.0ms pre-process, 149.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 155.1ms\n",
      "Speed: 0.0ms pre-process, 155.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 148.2ms\n",
      "Speed: 0.0ms pre-process, 148.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 150.8ms\n",
      "Speed: 0.0ms pre-process, 150.8ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 146.9ms\n",
      "Speed: 0.0ms pre-process, 146.9ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 145.3ms\n",
      "Speed: 0.0ms pre-process, 145.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 148.1ms\n",
      "Speed: 1.0ms pre-process, 148.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 145.9ms\n",
      "Speed: 0.0ms pre-process, 145.9ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 145.4ms\n",
      "Speed: 1.0ms pre-process, 145.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 168.1ms\n",
      "Speed: 0.0ms pre-process, 168.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 141.8ms\n",
      "Speed: 0.0ms pre-process, 141.8ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 144.2ms\n",
      "Speed: 0.0ms pre-process, 144.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 167.4ms\n",
      "Speed: 1.1ms pre-process, 167.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 158.7ms\n",
      "Speed: 0.0ms pre-process, 158.7ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 153.5ms\n",
      "Speed: 0.0ms pre-process, 153.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 150.7ms\n",
      "Speed: 1.0ms pre-process, 150.7ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 151.6ms\n",
      "Speed: 0.0ms pre-process, 151.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 147.4ms\n",
      "Speed: 1.0ms pre-process, 147.4ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 145.0ms\n",
      "Speed: 1.0ms pre-process, 145.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 147.7ms\n",
      "Speed: 0.0ms pre-process, 147.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 147.6ms\n",
      "Speed: 0.0ms pre-process, 147.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 142.7ms\n",
      "Speed: 1.0ms pre-process, 142.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 144.5ms\n",
      "Speed: 1.0ms pre-process, 144.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 145.7ms\n",
      "Speed: 0.0ms pre-process, 145.7ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 143.0ms\n",
      "Speed: 2.2ms pre-process, 143.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 144.9ms\n",
      "Speed: 1.0ms pre-process, 144.9ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 147.4ms\n",
      "Speed: 1.2ms pre-process, 147.4ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 145.5ms\n",
      "Speed: 0.0ms pre-process, 145.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 142.0ms\n",
      "Speed: 0.0ms pre-process, 142.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 148.5ms\n",
      "Speed: 1.0ms pre-process, 148.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 147.7ms\n",
      "Speed: 1.0ms pre-process, 147.7ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 134.8ms\n",
      "Speed: 1.0ms pre-process, 134.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 144.2ms\n",
      "Speed: 1.0ms pre-process, 144.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 142.8ms\n",
      "Speed: 0.0ms pre-process, 142.8ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 147.2ms\n",
      "Speed: 0.0ms pre-process, 147.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 153.6ms\n",
      "Speed: 0.0ms pre-process, 153.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 141.5ms\n",
      "Speed: 0.0ms pre-process, 141.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 147.5ms\n",
      "Speed: 0.0ms pre-process, 147.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 151.8ms\n",
      "Speed: 0.0ms pre-process, 151.8ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 147.5ms\n",
      "Speed: 2.4ms pre-process, 147.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 147.6ms\n",
      "Speed: 0.0ms pre-process, 147.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 159.5ms\n",
      "Speed: 2.2ms pre-process, 159.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 145.7ms\n",
      "Speed: 1.0ms pre-process, 145.7ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 149.3ms\n",
      "Speed: 0.0ms pre-process, 149.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 148.3ms\n",
      "Speed: 1.0ms pre-process, 148.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 159.9ms\n",
      "Speed: 1.3ms pre-process, 159.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 158.3ms\n",
      "Speed: 0.0ms pre-process, 158.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 152.8ms\n",
      "Speed: 1.0ms pre-process, 152.8ms inference, 0.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 161.4ms\n",
      "Speed: 1.0ms pre-process, 161.4ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 145.1ms\n",
      "Speed: 0.0ms pre-process, 145.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 154.6ms\n",
      "Speed: 0.0ms pre-process, 154.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 155.1ms\n",
      "Speed: 0.0ms pre-process, 155.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 153.0ms\n",
      "Speed: 1.0ms pre-process, 153.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 154.5ms\n",
      "Speed: 0.0ms pre-process, 154.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 156.9ms\n",
      "Speed: 0.0ms pre-process, 156.9ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 152.9ms\n",
      "Speed: 1.0ms pre-process, 152.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 152.0ms\n",
      "Speed: 1.0ms pre-process, 152.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 147.8ms\n",
      "Speed: 0.0ms pre-process, 147.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 147.3ms\n",
      "Speed: 1.0ms pre-process, 147.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 147.7ms\n",
      "Speed: 0.0ms pre-process, 147.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 141.4ms\n",
      "Speed: 0.0ms pre-process, 141.4ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 149.2ms\n",
      "Speed: 0.0ms pre-process, 149.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 156.9ms\n",
      "Speed: 0.0ms pre-process, 156.9ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 157.3ms\n",
      "Speed: 0.0ms pre-process, 157.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 151.9ms\n",
      "Speed: 0.0ms pre-process, 151.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 154.0ms\n",
      "Speed: 0.0ms pre-process, 154.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 151.0ms\n",
      "Speed: 0.0ms pre-process, 151.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 151.2ms\n",
      "Speed: 0.0ms pre-process, 151.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 167.0ms\n",
      "Speed: 1.2ms pre-process, 167.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 175.8ms\n",
      "Speed: 0.0ms pre-process, 175.8ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 180.7ms\n",
      "Speed: 1.1ms pre-process, 180.7ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 173.5ms\n",
      "Speed: 0.5ms pre-process, 173.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 163.2ms\n",
      "Speed: 0.0ms pre-process, 163.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 158.4ms\n",
      "Speed: 0.0ms pre-process, 158.4ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 158.5ms\n",
      "Speed: 1.0ms pre-process, 158.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 157.1ms\n",
      "Speed: 0.0ms pre-process, 157.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 153.1ms\n",
      "Speed: 0.0ms pre-process, 153.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 152.7ms\n",
      "Speed: 0.0ms pre-process, 152.7ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 162.5ms\n",
      "Speed: 0.0ms pre-process, 162.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 160.5ms\n",
      "Speed: 0.0ms pre-process, 160.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 161.3ms\n",
      "Speed: 0.0ms pre-process, 161.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 153.2ms\n",
      "Speed: 0.0ms pre-process, 153.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 153.9ms\n",
      "Speed: 0.0ms pre-process, 153.9ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 158.1ms\n",
      "Speed: 0.0ms pre-process, 158.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 152.5ms\n",
      "Speed: 0.0ms pre-process, 152.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 148.6ms\n",
      "Speed: 0.0ms pre-process, 148.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 154.4ms\n",
      "Speed: 0.0ms pre-process, 154.4ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 156.5ms\n",
      "Speed: 1.0ms pre-process, 156.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 150.3ms\n",
      "Speed: 1.1ms pre-process, 150.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 154.1ms\n",
      "Speed: 1.0ms pre-process, 154.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 157.6ms\n",
      "Speed: 0.0ms pre-process, 157.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 150.2ms\n",
      "Speed: 0.5ms pre-process, 150.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 158.1ms\n",
      "Speed: 1.4ms pre-process, 158.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 155.0ms\n",
      "Speed: 0.0ms pre-process, 155.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 161.2ms\n",
      "Speed: 0.0ms pre-process, 161.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 158.9ms\n",
      "Speed: 1.0ms pre-process, 158.9ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 154.9ms\n",
      "Speed: 0.0ms pre-process, 154.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 150.6ms\n",
      "Speed: 1.0ms pre-process, 150.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 152.8ms\n",
      "Speed: 1.0ms pre-process, 152.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 146.5ms\n",
      "Speed: 0.0ms pre-process, 146.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 147.5ms\n",
      "Speed: 1.0ms pre-process, 147.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 148.6ms\n",
      "Speed: 0.0ms pre-process, 148.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 149.1ms\n",
      "Speed: 1.0ms pre-process, 149.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 152.5ms\n",
      "Speed: 1.3ms pre-process, 152.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "import time\n",
    "from time import time\n",
    "from ultralytics import YOLO\n",
    "\n",
    "from supervision.draw.color import ColorPalette,Color\n",
    "from supervision.tools.detections import Detections, BoxAnnotator\n",
    "\n",
    "import pyglet #for sound alert\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(\"Using Device: \", device)\n",
    "\n",
    "model = YOLO(\"M:/CV/ACC_POC/weights/yolo8n_160epochs.pt\")  # load a pretrained YOLOv8n model\n",
    "model.fuse()\n",
    "CLASS_NAMES_DICT = model.model.names\n",
    "\n",
    "\n",
    "box_annotator = BoxAnnotator(color=ColorPalette(), thickness=2, text_thickness=2, text_scale=1)\n",
    "\n",
    "#box_annotator_noHelmet = BoxAnnotator(color=Color(r=255,g=0,b=0), thickness=3, text_thickness=3, text_scale=1.5)\n",
    "#box_annotator_Helmet = BoxAnnotator(color=Color(r=0,g=255,b=0), thickness=3, text_thickness=3, text_scale=1.5)\n",
    "\n",
    "def plot_bboxes(results,frame,color_code):\n",
    "    xyxys = []\n",
    "    confidences = []\n",
    "    class_ids = []\n",
    "\n",
    "    # Extract detections for person class\n",
    "    for result in results[0]:\n",
    "        class_id = result.boxes.cls.cpu().numpy().astype(int)\n",
    "        if class_id == 1:\n",
    "            xyxys.append(result.boxes.xyxy.cpu().numpy())\n",
    "            confidences.append(result.boxes.conf.cpu().numpy())\n",
    "            class_ids.append(result.boxes.cls.cpu().numpy().astype(int))\n",
    "        \n",
    "    # Setup detections for visualization\n",
    "    detections = Detections(\n",
    "                xyxy=results[0].boxes.xyxy.cpu().numpy(),\n",
    "                confidence=results[0].boxes.conf.cpu().numpy(),\n",
    "                class_id=results[0].boxes.cls.cpu().numpy().astype(int),\n",
    "                )\n",
    "    \n",
    "    # Format custom labels\n",
    "    labels = [f\"{CLASS_NAMES_DICT[class_id]} {confidence:0.2f}\"\n",
    "    for _, confidence, class_id, tracker_id\n",
    "    in detections]\n",
    "    \n",
    "    # Annotate and display frame\n",
    "    if color_code == 'red':\n",
    "        frame = box_annotator.annotate(frame=frame, detections=detections, labels=labels)\n",
    "    else:\n",
    "        frame = box_annotator.annotate(frame=frame, detections=detections, labels=labels)\n",
    "    \n",
    "    return frame\n",
    "\n",
    "\n",
    "def sound_alert(frame):\n",
    "        saved_nohelmetimages_counter=1\n",
    "        music_voice = pyglet.resource.media('beep_alert_ok.mp3')\n",
    "        music_voice.play()\n",
    "        cv2.imwrite('Saved_NoHelmet/'+str(saved_nohelmetimages_counter)+'.jpg',frame)\n",
    "\n",
    "\n",
    "def stream_vid(capture_index):\n",
    "    \n",
    "    res_count=0 \n",
    "    first_alert=50\n",
    "    second_alert=200\n",
    "    third_alert=500\n",
    "    fourth_alert=1000\n",
    "\n",
    "    cap = cv2.VideoCapture(capture_index)\n",
    "    assert cap.isOpened()\n",
    "    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 720)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)\n",
    "\n",
    "    while True:\n",
    "        start_time = time()\n",
    "        ret, frame = cap.read()\n",
    "        assert ret\n",
    "\n",
    "        results = model(frame)\n",
    "        ##\n",
    "        xyxy=[]\n",
    "        class_id=[]\n",
    "        for result in results[0]:\n",
    "            xyxy.append(result.boxes.xyxy.cpu().numpy())\n",
    "            class_id = result.boxes.cls.cpu().numpy().astype(int)\n",
    "        \n",
    "        if class_id==1:\n",
    "            res_count+=1\n",
    "        else:\n",
    "            pass\n",
    "            \n",
    "        if res_count == first_alert:\n",
    "            sound_alert(frame)  \n",
    "        elif res_count == second_alert:\n",
    "            sound_alert(frame)\n",
    "        elif res_count == third_alert:\n",
    "            sound_alert(frame)\n",
    "        elif res_count == fourth_alert:\n",
    "            sound_alert(frame)\n",
    "            res_count=0\n",
    "        ##\n",
    "\n",
    "        if class_id == 1:\n",
    "            frame =  plot_bboxes(results, frame,'red')\n",
    "            cv2.putText(frame, \"Warning!\", (50,300), cv2.FONT_HERSHEY_SIMPLEX, 2, (0,0,255), 4)\n",
    "        else:\n",
    "            frame =  plot_bboxes(results, frame,'green')\n",
    "\n",
    "        end_time = time()\n",
    "        fps = 1/np.round(end_time - start_time, 2)\n",
    "\n",
    "\n",
    "        cv2.putText(frame, f'FPS: {int(fps)}', (10,600), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,0), 2)\n",
    "        cv2.imshow('YOLOv8 Detection', frame)\n",
    "        if cv2.waitKey(10) == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "capture_index='M:/CV/ACC_POC/videos/2.mp4'\n",
    "stream_vid(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backup of MAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "from time import time\n",
    "from ultralytics import YOLO\n",
    "\n",
    "from supervision.draw.color import ColorPalette\n",
    "from supervision.tools.detections import Detections, BoxAnnotator\n",
    "\n",
    "device = 'cpu' if torch.cuda.is_available() else 'cpu'\n",
    "print(\"Using Device: \", device)\n",
    "\n",
    "model = YOLO(\"M:/CV/ACC_POC/weights/yolo8n_200epochs.pt\")  # load a pretrained YOLOv8n model\n",
    "model.fuse()\n",
    "CLASS_NAMES_DICT = model.model.names\n",
    "box_annotator = BoxAnnotator(color=ColorPalette(), thickness=3, text_thickness=3, text_scale=1.5)\n",
    "\n",
    "\n",
    "def plot_bboxes(results,frame):\n",
    "    xyxys = []\n",
    "    confidences = []\n",
    "    class_ids = []\n",
    "    \n",
    "    # Extract detections for person class\n",
    "    for result in results[0]:\n",
    "        class_id = result.boxes.cls.cpu().numpy().astype(int)\n",
    "        \n",
    "        if class_id == 1:\n",
    "            \n",
    "            xyxys.append(result.boxes.xyxy.cpu().numpy())\n",
    "            confidences.append(result.boxes.conf.cpu().numpy())\n",
    "            class_ids.append(result.boxes.cls.cpu().numpy().astype(int))\n",
    "        \n",
    "    # Setup detections for visualization\n",
    "    detections = Detections(\n",
    "                xyxy=results[0].boxes.xyxy.cpu().numpy(),\n",
    "                confidence=results[0].boxes.conf.cpu().numpy(),\n",
    "                class_id=results[0].boxes.cls.cpu().numpy().astype(int),\n",
    "                )\n",
    "    \n",
    "    # Format custom labels\n",
    "    labels = [f\"{CLASS_NAMES_DICT[class_id]} {confidence:0.2f}\"\n",
    "    for _, confidence, class_id, tracker_id\n",
    "    in detections]\n",
    "    \n",
    "    # Annotate and display frame\n",
    "    frame = box_annotator.annotate(frame=frame, detections=detections, labels=labels)\n",
    "    \n",
    "    return frame\n",
    "\n",
    "\n",
    "def stream_vid(capture_index):\n",
    "    cap = cv2.VideoCapture(capture_index)\n",
    "    assert cap.isOpened()\n",
    "    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)\n",
    "\n",
    "    while True:\n",
    "        start_time = time()\n",
    "        ret, frame = cap.read()\n",
    "        assert ret\n",
    "\n",
    "        results = model(frame)\n",
    "        frame =  plot_bboxes(results, frame)\n",
    "\n",
    "        end_time = time()\n",
    "        fps = 1/np.round(end_time - start_time, 2)\n",
    "\n",
    "        cv2.putText(frame, f'FPS: {int(fps)}', (20,70), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0,255,0), 2)\n",
    "        cv2.imshow('YOLOv8 Detection', frame)\n",
    "        if cv2.waitKey(10) == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "\n",
    "capture_index='M:/CV/ACC_POC/videos/4.mp4'\n",
    "stream_vid(0)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beep_alert():\n",
    "        beep = pyglet.resource.media('beep_alert.mp3')\n",
    "        beep.play()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "logo=cv2.imread('warning.png')\n",
    "res=cv2.resize(logo,(100,100))\n",
    "cv2.imwrite('resized_logo.png',res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7af9a311cdaeb9a89e812825701599565e63239dd7e51185ccf6d02508f0397a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
